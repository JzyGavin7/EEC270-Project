{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "EEC 270 Website Fingerprinting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "data = pd.read_csv('data_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# seq_len, batch, feature_len\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(25, 100, 3, batch_first=True)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(100, 31),\n",
    "            nn.BatchNorm1d(31),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, source):\n",
    "        output, _ = self.lstm(source.view(source.shape[0], 1, 25))\n",
    "        output = output[:,-1]\n",
    "        return self.linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "X, y = data.values[:,:-1], data.values[:,-1]\n",
    "X, y = torch.Tensor(X), torch.Tensor(y)\n",
    "trans_X = X.reshape((len(X), 25))\n",
    "trans_X_ = X.reshape((len(X), 5, 5))\n",
    "X = trans_X\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Split dataset into train and valid, with a ratio of 4:1\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "random.shuffle(indices)\n",
    "split = int(np.floor(0.2 * dataset_size))\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=train_sampler\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=valid_sampler\n",
    ")\n",
    "\n",
    "X_test, y_test = None, None\n",
    "for _, test_sample in enumerate(valid_loader):\n",
    "    X_test, y_test = test_sample[0], test_sample[1].long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss: 3.3674535751342773 Accuracy: 0.10684474123539232\n",
      "Epoch 100 Training Loss: 1.69565749168396 Accuracy: 0.5258764607679466\n",
      "Epoch 200 Training Loss: 1.4455851316452026 Accuracy: 0.5325542570951586\n",
      "Epoch 300 Training Loss: 1.3271284103393555 Accuracy: 0.5342237061769616\n",
      "Epoch 400 Training Loss: 1.160200595855713 Accuracy: 0.5275459098497496\n",
      "Epoch 500 Training Loss: 1.2462680339813232 Accuracy: 0.5492487479131887\n",
      "Epoch 600 Training Loss: 1.0421981811523438 Accuracy: 0.5409015025041736\n",
      "Epoch 700 Training Loss: 1.0185291767120361 Accuracy: 0.5425709515859767\n",
      "Epoch 800 Training Loss: 1.0275272130966187 Accuracy: 0.5392320534223706\n",
      "Epoch 900 Training Loss: 0.9433490633964539 Accuracy: 0.5358931552587646\n",
      "Epoch 1000 Training Loss: 0.9827002286911011 Accuracy: 0.5442404006677797\n",
      "Epoch 1100 Training Loss: 0.9262630343437195 Accuracy: 0.5459098497495827\n",
      "Epoch 1200 Training Loss: 0.9256651401519775 Accuracy: 0.5342237061769616\n",
      "Epoch 1300 Training Loss: 0.8706201314926147 Accuracy: 0.5492487479131887\n",
      "Epoch 1400 Training Loss: 0.7990036606788635 Accuracy: 0.5358931552587646\n",
      "Epoch 1500 Training Loss: 0.8669804334640503 Accuracy: 0.5409015025041736\n",
      "Epoch 1600 Training Loss: 0.7946584224700928 Accuracy: 0.5542570951585977\n",
      "Epoch 1700 Training Loss: 0.8440990447998047 Accuracy: 0.5542570951585977\n",
      "Epoch 1800 Training Loss: 0.8224250078201294 Accuracy: 0.5358931552587646\n",
      "Epoch 1900 Training Loss: 0.7179756760597229 Accuracy: 0.5475792988313857\n",
      "Epoch 2000 Training Loss: 0.7685904502868652 Accuracy: 0.5392320534223706\n",
      "Epoch 2100 Training Loss: 0.757757842540741 Accuracy: 0.5459098497495827\n",
      "Epoch 2200 Training Loss: 0.8776465654373169 Accuracy: 0.5342237061769616\n",
      "Epoch 2300 Training Loss: 0.7484418153762817 Accuracy: 0.5325542570951586\n",
      "Epoch 2400 Training Loss: 0.7389260530471802 Accuracy: 0.5375626043405676\n",
      "Epoch 2500 Training Loss: 0.6574169397354126 Accuracy: 0.5475792988313857\n",
      "Epoch 2600 Training Loss: 0.7344498038291931 Accuracy: 0.5575959933222037\n",
      "Epoch 2700 Training Loss: 0.7507173418998718 Accuracy: 0.5292153589315526\n",
      "Epoch 2800 Training Loss: 0.8973557353019714 Accuracy: 0.5375626043405676\n",
      "Epoch 2900 Training Loss: 0.7932263612747192 Accuracy: 0.5258764607679466\n",
      "Epoch 3000 Training Loss: 0.7922095060348511 Accuracy: 0.5225375626043406\n",
      "Epoch 3100 Training Loss: 0.7333906888961792 Accuracy: 0.5208681135225376\n",
      "Epoch 3200 Training Loss: 0.6436333060264587 Accuracy: 0.5208681135225376\n",
      "Epoch 3300 Training Loss: 0.7723305821418762 Accuracy: 0.5258764607679466\n",
      "Epoch 3400 Training Loss: 0.7289579510688782 Accuracy: 0.5258764607679466\n",
      "Epoch 3500 Training Loss: 0.7356747984886169 Accuracy: 0.5258764607679466\n",
      "Epoch 3600 Training Loss: 0.5227172374725342 Accuracy: 0.5292153589315526\n",
      "Epoch 3700 Training Loss: 0.5596969127655029 Accuracy: 0.5041736227045075\n",
      "Epoch 3800 Training Loss: 0.6358889937400818 Accuracy: 0.5208681135225376\n",
      "Epoch 3900 Training Loss: 0.6289318799972534 Accuracy: 0.5258764607679466\n",
      "Epoch 4000 Training Loss: 0.6737409830093384 Accuracy: 0.5158597662771286\n",
      "Epoch 4100 Training Loss: 0.6587309241294861 Accuracy: 0.5225375626043406\n",
      "Epoch 4200 Training Loss: 0.6635847687721252 Accuracy: 0.5191986644407346\n",
      "Epoch 4300 Training Loss: 0.648488461971283 Accuracy: 0.5258764607679466\n",
      "Epoch 4400 Training Loss: 0.647991955280304 Accuracy: 0.5191986644407346\n",
      "Epoch 4500 Training Loss: 0.5749296545982361 Accuracy: 0.5175292153589316\n",
      "Epoch 4600 Training Loss: 0.7406002879142761 Accuracy: 0.5208681135225376\n",
      "Epoch 4700 Training Loss: 0.5741220116615295 Accuracy: 0.5242070116861436\n",
      "Epoch 4800 Training Loss: 0.6584008932113647 Accuracy: 0.5275459098497496\n",
      "Epoch 4900 Training Loss: 0.5804163217544556 Accuracy: 0.5125208681135225\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./lstm')\n",
    "\n",
    "model = LSTM()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5000):\n",
    "    for _, sample in enumerate(train_loader, 0):\n",
    "        model.zero_grad()\n",
    "        inputs, labels = sample\n",
    "        labels = labels.long()\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        # Training loss\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for sample in valid_loader:\n",
    "            inputs, labels = sample\n",
    "            labels = labels.long()\n",
    "            pred = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    writer.add_scalar('Accuracy/test', correct/total, epoch)\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch', epoch, 'Training Loss:', loss.item(), 'Accuracy:', correct/total)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.542713567839196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(X_test)\n",
    "accuracy_score(pred.argmax(axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'lstm.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef9226f5f281bed155f6877abe961f8893e93036b236b1a7e5395de73a55139a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
